{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal of this notebook is to compare the achieveable energy resoultion of the optimal filter (gen2) with that of the most successful machine learning model, using the same resonator, readout, and noise parameters. The plan is to have the optimal filter template and filter generated in the same way that would be done during a MEC run, using a dataset consisting of pulses of the same height. The machine learning model will have been trained on a variety of pulses within the same range. The largest pulse height used to train the machine learning model will be used to generate the template/filter in the optimal filter code. The results will then be compared on the single pulse height. The process will be repeated, generating the optimal filter template/filter with one pulse but the input phase timestream will have varied pulse heights using the same range that was used when training the model."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Single Pulse Height"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import pathlib\n",
    "from pathlib import Path\n",
    "import os\n",
    "import random\n",
    "import torch\n",
    "\n",
    "from torch.utils.data import TensorDataset\n",
    "from mkidreadoutanalysis.quasiparticletimestream import QuasiparticleTimeStream\n",
    "from mkidreadoutanalysis.resonator import Resonator, RFElectronics, ReadoutPhotonResonator, FrequencyGrid, LineNoise\n",
    "from mkidreadoutanalysis.optimal_filters.make_filters import Calculator\n",
    "from mkidreadoutanalysis.mkidnoiseanalysis import apply_lowpass_filter, compute_r\n",
    "from mkidcore.config import ConfigThing\n",
    "from mlcore.dataset import load_training_data\n",
    "\n",
    "from mlcore.models import BranchedConvReg\n",
    "from mlcore.training import make_predictions\n",
    "from mlcore.dataset import load_training_data, stream_to_arrival, create_windows\n",
    "from mlcore.eval import plot_stream_data"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "First, the calibration data to be used for generating the optimal filter template/filters needs to be imported.\n",
    "This data is independent of the actual signal data but will also be used as input to the machine learning model so that\n",
    "the final performance can be compared to the optimal filter. "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define common parameters\n",
    "EDGE_PAD = 100\n",
    "NOISE_SCALE = 30\n",
    "NUM_SAMPLES = 30000\n",
    "WINDOW = 1000\n",
    "MAG = 1.000\n",
    "FS = 1e6\n",
    "NOISE_ON = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define data storage parent location\n",
    "data_parent_dir = os.environ['ML_DATA_DIR']\n",
    "data_dir = Path(data_parent_dir + '/pulses/test/single_pulse/variable_qp_density/normalized_iq')\n",
    "cal_p = Path(data_dir, f'vp_single_num{NUM_SAMPLES}_window{WINDOW}_mag{int(MAG * 1000)}_noisescale{NOISE_SCALE}_pad{EDGE_PAD}.npz')\n",
    "\n",
    "# Import the photon arrival data from the stored calibration data\n",
    "cal_i, cal_q, cal_ml_phase_resp, cal_photon_arrs = load_training_data(cal_p, labels=('i', 'q', 'phase_response', 'photon_arrivals'))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The goal is to generate a phase response timestream using a stitched together version of all of the calibration samples,\n",
    "which currently are stored in the form that allows for training the machine learning model. There are 30000 \"training samples\",\n",
    "each with a length of 1000 time samples. There is a photon event somewhere within the middle `1000 - 2 * edge_pad` time samples in each training\n",
    "sample. Since the optimal filter simulator is designed to accept a single phase response stream, the photon arrival times will need to be unwrapped\n",
    "and then used to create a phase response time stream, using the ***same resonator, readout, and noise objects used in the machine learning model training set***. Alternatively, the phase timestreams stored in the calibration data\n",
    "could be stitched together in this way, but the noise additions at the window edges would most likely not be physical."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the calibration photon arrival array\n",
    "cal_photon_arrs = cal_photon_arrs.flatten()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the ML model matched qpt/resonator/noise/readout objects to be used to create the phase response timestream\n",
    "\n",
    "qptimestream = QuasiparticleTimeStream(FS, 30) # Need the qpt timestream to have a length equal to the calibration stream\n",
    "qptimestream.photon_arrivals = cal_photon_arrs # Manually setting the photon arrivals as opposed to having the object generate its own\n",
    "qptimestream.gen_quasiparticle_pulse(magnitude=0.6)\n",
    "_ = qptimestream.populate_photons()\n",
    "\n",
    "# original amplitudes: 0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.01\n",
    "RES = Resonator(f0=4.0012e9, qi=200000, qc=15000, xa=1e-9, a=0, tls_scale=1e2)\n",
    "FREQ_GRID = FrequencyGrid(fc=RES.f0, points=1000, span=500e6)\n",
    "LINE_NOISE = LineNoise(freqs=[60, 50e3, 100e3, 250e3, -300e3, 300e3, 500e3],\n",
    "                        #amplitudes=[0, 0, 0, 0, 0, 0, 0],\n",
    "                        #amplitudes=[0.005, 0.005, 0.005, 0.005, 0.005, 0.005, 0.0001],\n",
    "                        amplitudes=[0.01, 0.01, 0.01, 0.01, 0.01, 0.01, 0.005],\n",
    "                        #amplitudes=[0.05, 0.05, 0.05, 0.05, 0.05, 0.05, 0.01],\n",
    "                        phases=[0, 0.5, 0,1.3,0.5, 0.2, 2.4],\n",
    "                        n_samples=100,\n",
    "                        fs=FS)\n",
    "RF = RFElectronics(gain=(3.0, 0, 0),\n",
    "                    phase_delay=0,\n",
    "                    white_noise_scale=30,\n",
    "                    line_noise=LINE_NOISE,\n",
    "                    cable_delay=50e-9)\n",
    "readout = ReadoutPhotonResonator(RES, qptimestream, FREQ_GRID, RF, noise_on=NOISE_ON)\n",
    "\n",
    "# Generate phase response time stream.\n",
    "cal_phase_response, _ = readout.basic_coordinate_transformation()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get an idea of the pulse shape of the calibration data\n",
    "plt.plot(np.arange(cal_phase_response[:1000].size),cal_phase_response[:1000])\n",
    "np.sum(cal_photon_arrs[cal_photon_arrs == 1]) # Number of pulses in the calibration set"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Before sending the phase response time stream to the optimal filter step, it needs to be low-pass filtered.\n",
    "# The following filter coefficients are pulled from the example notebook in the mkidreadoutanalysis package.\n",
    "# Current 8-Tap Equirippple Lowpass Exported from MATLAB\n",
    "coe = np.array([-0.08066211966627938,\n",
    "                0.02032901400427789,\n",
    "                0.21182262325068868,\n",
    "                0.38968583545138658,\n",
    "                0.38968583545138658,\n",
    "                0.21182262325068868,\n",
    "                0.02032901400427789,\n",
    "                -0.08066211966627938])\n",
    "low_pass_cal_resp = apply_lowpass_filter(coe, cal_phase_response)\n",
    "plt.plot(np.arange(low_pass_cal_resp[:1000].size), low_pass_cal_resp[:1000])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the phase response timestream has been created based on the photon arrivals in the calibration data, the accompanying optimal filter can be built"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import a ConfigThing object to store optimal filter nerd knob values\n",
    "cfg_thing = ConfigThing()\n",
    "\n",
    "# Now define/store the values in the ConfigThing object\n",
    "cfg_thing.registerfromkvlist(\n",
    "    (\n",
    "        ('dt', 1/FS), # Sampling interval (in secs)\n",
    "        ('fit', True), # This flag instructs the code to fit or not to fit the created template of photon pulses. The template is made by averaging all the pulses in the passed in phase stream after median subtraction. (by default)\n",
    "        ('summary_plot', True), # The summary plot gives information about the template creation, filtering and the fit to the template (if enabled)\n",
    "        ('pulses.unwrap', False), # Phase unwrapping refers to recovering the true phase of a signal after it has been \"wrapped\" into an arbitrary range (E.g. from -pi to pi). Discontinuities in the wrapped stream typically indicate the phase was wrapped. \n",
    "        ('pulses.fallback_template', 'default'), # This tells the code which fallback template to use in case making a \"good\" template couldn't be made from the data (typically due to not enough pulses in the passed in stream.)\n",
    "        ('pulses.ntemplate', 1000), # Used in the pulse averaging function. Essentially the length of the pulse template.\n",
    "        ('pulses.offset', 20), # Offset from the start of the template \"window\" where the pulse will start.\n",
    "        ('pulses.threshold', 8), # Only pulses greater than this value multiplied by std dev. of all the filtered pulses will be included in the output.\n",
    "        ('pulses.separation', 50), # A pulse arriving in a time window shorter than this value (in us) with respect to the previous pulse will be discarded.\n",
    "        ('pulses.min_pulses', 10000), # Number of pulses needed to make a \"good\" template.\n",
    "        ('noise.nwindow', 1000), # The size of the overlapping segment used to create the PSD of the phase stream using Welch's method. This is similar to the window size in the STFT when creating Spectrograms (it's called Periodogram).\n",
    "        ('noise.isolation', 100), # When making the noise spectrum for the data using Welch's method, having pulses too close to each other can skew results. This parameter helps determine how close is too close.\n",
    "        ('noise.max_windows', 2000), # maximum number of windows of length nwindow needed when creating the noise spectrum of the phase stream using Welch's method.\n",
    "        ('noise.max_noise', 5000), # cant seem to find this value anywhere in the Calculator class\n",
    "        ('template.percent', 80), # Pulses that lie outside the middle \"percent\" percentiles are discarded when creating the pulse template. Higher number means more fringe pulses are used when making the template.\n",
    "        ('template.cutoff', 0.1), # The filter response of the chosen filter is 0 for frequencies above this value (units in 1/dt)\n",
    "        ('template.min_tau', 5), # Tau seems to be variable that parameterizes the integral of the normalized template. This parameter describes the minimum value that tau can have to signify a \"good\" template.\n",
    "        ('template.max_tau', 500), # In the context of the previous parameter, this is the max value of tau to consider a template a \"good\" template\n",
    "        ('template.fit', 'triple_exponential'), # If fitting the template, this is the fitting function to use. These are defined in the templates.py file.\n",
    "        ('filter.filter_type', 'wiener'), # The type of filter to use for the optimal filter. These are defined in the filters.py file.\n",
    "        ('filter.nfilter', 100), # The number of taps to use in the chosen filter. \n",
    "                                # Jenny Note: For messing around this should be closer to 1000 and ntemplate should be increased to be 5-10x nfilter\n",
    "                                # Jenny Note: Need to make sure filter is periodic and this gets hard when the filter is short\n",
    "        ('filter.normalize', True) # If true, normalizes the filter to a unit response.\n",
    "    ),\n",
    "namespace='' # Not relevant for the optimal filter code.\n",
    ")\n",
    "\n",
    "optimal_filter = Calculator(low_pass_cal_resp, config=cfg_thing, name='calibration')\n",
    "optimal_filter.calculate()\n",
    "optimal_filter.plot()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the optimal filter created and the template generated based on the calibration data, need to now get the calibration data through the highest performing ml model."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define saved model path\n",
    "MODEL_DIR = pathlib.Path().cwd() / 'best_models'\n",
    "MODEL_FNAME = 'cnn_reg_1692139221.pt'\n",
    "\n",
    "# Device determination\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "print(f'Using device: \"{device}\"')\n",
    "\n",
    "# Create model instance and load trained model\n",
    "model = BranchedConvReg(in_channels=2, h_hidden_units=100, h_hidden_layers=3)\n",
    "model.load_state_dict(torch.load(MODEL_DIR / MODEL_FNAME, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Transform data such that it can be passed through the model (conversion from np.array to torch.tensor, split the input and target data, make into a Pytorch Dataset)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "I = readout.normalized_iq.real\n",
    "Q = readout.normalized_iq.imag"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "To keep from having to make different data files for each change to the noise parameters, will just create\n",
    "the dataset dynamically using the photon arrival timestream from an existing data file. In addition to the\n",
    "previously mentioned increase to agility, this will make the results between the ML and OFC more comparable."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reshape the arrays such that they can be used in the ML data transformation\n",
    "# functions.\n",
    "I = I.reshape(30000, 1000)\n",
    "Q = Q.reshape(30000, 1000)\n",
    "cal_phase_response = cal_phase_response.reshape(30000, 1000)\n",
    "cal_photon_arrs = cal_photon_arrs.reshape(30000, 1000)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to expand the dimensions for the i and q streams\n",
    "# since they will be used as input samples.\n",
    "cal_i = np.expand_dims(I, axis=1)\n",
    "cal_q = np.expand_dims(Q, axis=1)\n",
    "\n",
    "# Get pulse heights and photon arrival values\n",
    "target_arrs_cal = stream_to_arrival(cal_photon_arrs)\n",
    "target_pulse_cal = np.min(cal_phase_response, axis=1, keepdims=True)\n",
    "\n",
    "# Now we want to convert the loaded data to tensors.\n",
    "# Shape for targets is NUM_SAMPLES x 1 x 2\n",
    "# Shape for inputs is NUM_SAMPLES x 2 x WINDOW_SIZE\n",
    "X_cal = torch.Tensor(np.hstack((cal_i, cal_q)))\n",
    "y_cal = torch.Tensor(np.stack((target_arrs_cal, target_pulse_cal), axis=2))\n",
    "\n",
    "# From the newly created tensors, create testing and training datasets\n",
    "cal_dataset = TensorDataset(X_cal, y_cal)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that the Pytorch dataset has been created from the calibration data, need to get the model predictions on the calibraiton data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick k random samples/labels from the test data and plot them along with the predictions\n",
    "cal_samples = []\n",
    "cal_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(cal_dataset), k=len(cal_dataset)): # random.sample randomly samples k elements from the given population without replacement; returns list of samples.\n",
    "    cal_samples.append(sample)\n",
    "    cal_labels.append(label)\n",
    "\n",
    "print(f'Sample Shape: {cal_samples[0].shape}, Label Shape: {cal_labels[0].shape}')\n",
    "preds = make_predictions(model, [x.unsqueeze(dim=0) for x in cal_samples], device=device) # returns a list\n",
    "print(f'Preds shape {preds[0].shape}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "With the model predictions on the calibration dataset know, the histograms of both the optimal filter phase response values and the models phase response values can be plotted."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Get pulses from the optimal filter with the threshold used when creating the template\n",
    "_ = optimal_filter.apply_filter()\n",
    "ofc_phase_preds, _ = optimal_filter.compute_responses(threshold=cfg_thing.get('pulses.threshold'))\n",
    "\n",
    "# Now randomly pick number of samples from the ml predictions based on the number of\n",
    "# pulses in the ofc phase preds\n",
    "sampled_ml_preds = [pred for pred in random.sample(preds, k=ofc_phase_preds.size)]\n",
    "\n",
    "# Create np array of the sampled ml preds\n",
    "model_phase_preds = np.array([pred[1] for pred in sampled_ml_preds])\n",
    "\n",
    "# Create the histograms of model and ofc predictions for pulse height\n",
    "n_bins = 200\n",
    "ml_counts, ml_bins = np.histogram(model_phase_preds, range=(-2.2, -1), bins=n_bins)\n",
    "ofc_counts, ofc_bins = np.histogram(ofc_phase_preds, range=(-2.2, -1), bins=n_bins)\n",
    "\n",
    "# Lets plot the histogram\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.stairs(ml_counts, ml_bins, label='ml')\n",
    "plt.stairs(ofc_counts, ofc_bins, label='ofc')\n",
    "plt.title('Predicted Pulse Heights')\n",
    "plt.xlabel('Pulse Height')\n",
    "plt.ylabel('Counts')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Verifying both are the same size\n",
    "print(ofc_phase_preds.size)\n",
    "print(model_phase_preds.size)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Now that we have filtered and raw peaks, we can use the machinery in the mkidreadoutanalysis package to determine R for both the optimal filter output and the model predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_r(ofc_phase_preds, plot=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "compute_r(model_phase_preds, plot=True)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "pipeline",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.4"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

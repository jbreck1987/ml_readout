{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models import ConvRegv2\n",
    "from mlcore.training import make_predictions\n",
    "from mlcore.eval import plot_stream_data\n",
    "from mlcore.dataset import load_training_data, stream_to_arrival, stream_to_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "MODEL_DIR = pathlib.Path().cwd() / 'trained_models'\n",
    "MODEL_FNAME = 'cnn_reg_1691256621.pt'\n",
    "RANDOM_SEED = 42\n",
    "TEST_RATIO = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EDGE_PAD = 10\n",
    "WINDOW_SIZE = 1000\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "if torch.cuda.is_available():\n",
    "  device = torch.device(\"cuda\")\n",
    "\n",
    "elif torch.backends.mps.is_available():\n",
    "  device = torch.device('mps')\n",
    "\n",
    "else:\n",
    "  device = torch.device(\"cpu\")\n",
    "print(f'Using device: \"{device}\"')\n",
    "\n",
    "model = ConvRegv2(2, BATCH_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_DIR / MODEL_FNAME, map_location=device))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset locations and load the training and test data\n",
    "test_dir = Path('../../../data/pulses/test/single_pulse/variable_qp_density/raw_iq')\n",
    "train_dir = Path('../../../data/pulses/train/single_pulse/variable_qp_density/raw_iq')\n",
    "fname = Path(f'vp_single_num{NUM_SAMPLES}_win{WINDOW_SIZE}_pad{EDGE_PAD}.npz')\n",
    "labels = ('i', 'q', 'photon_arrivals', 'phase_response')\n",
    "i_test, q_test, arrs_test, theta1_test = load_training_data(test_dir / fname, labels=labels)\n",
    "i_train, q_train, arrs_train, theta1_train = load_training_data(train_dir / fname, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to expand the dimensions for the i and q streams\n",
    "# since they will be used as input samples.\n",
    "i_test = np.expand_dims(i_test, axis=1)\n",
    "i_train = np.expand_dims(i_train, axis=1)\n",
    "q_test = np.expand_dims(q_test, axis=1)\n",
    "q_train = np.expand_dims(q_train, axis=1)\n",
    "\n",
    "# Get pulse heights and photon arrival values\n",
    "target_arrs_train = stream_to_arrival(arrs_train)\n",
    "target_arrs_test = stream_to_arrival(arrs_test)\n",
    "target_pulse_train = stream_to_height(arrs_train, theta1_train)\n",
    "target_pulse_test = stream_to_height(arrs_test, theta1_test)\n",
    "\n",
    "# Now we want to convert the loaded data to tensors.\n",
    "# Shape for targets is NUM_SAMPLES x 1 x 2\n",
    "# Shape for inputs is NUM_SAMPLES x 2 x WINDOW_SIZE\n",
    "X_train = torch.Tensor(np.hstack((i_train, q_train))) \n",
    "X_test = torch.Tensor(np.hstack((i_test, q_test)))\n",
    "y_train = torch.Tensor(np.stack((target_arrs_train, target_pulse_train), axis=2)) \n",
    "y_test = torch.Tensor(np.stack((target_arrs_test, target_pulse_test), axis=2))\n",
    "\n",
    "# From the newly created tensors, create testing and training datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick k random samples/labels from the test data and plot them along with the predictions\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_dataset), k=len(test_dataset)): # random.sample samples k elements from the given population without replacement; returns list of samples.\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "print(f'Test Sample Shape: {test_samples[0].shape}, Test Label Shape: {test_labels[0].shape}')\n",
    "preds = make_predictions(model, [x.unsqueeze(dim=0) for x in test_samples]) # returns a tensor\n",
    "print(f'Preds shape {preds[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the train/test loss was so low and the absolute error was low, lets determine the difference between the predicted and\n",
    "# target arival times and plot this\n",
    "# Note the multiplication by 1000 to get back to the arrival time element\n",
    "arrival_diff = [torch.abs(WINDOW_SIZE * y_pred[0][0][0] - WINDOW_SIZE * y_true[0][0]).item() for y_pred, y_true in zip(preds, test_labels)]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Photon Arrival Time Error')\n",
    "plt.plot(np.arange(len(arrival_diff)), arrival_diff)\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Error (samples)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the error is known, let's plot the actual values for both the predictions and the targets\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Photon Arrival Time Predicted vs Target')\n",
    "#plt.plot(np.arange(len(preds)), [WINDOW_SIZE*pred[0][0][0].item() for pred in preds], label='Predicted')\n",
    "#plt.plot(np.arange(len(test_labels)), [WINDOW_SIZE*label[0][0].item() for label in test_labels], label='Target')\n",
    "plt.scatter(np.arange(len(preds)), [WINDOW_SIZE*pred[0][0][0].item() for pred in preds], marker='+', label='Predicted')\n",
    "plt.scatter(np.arange(len(test_labels)), [WINDOW_SIZE*label[0][0].item() for label in test_labels], label='Target')\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Photon Arrival (sample)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do the same with the pulse height\n",
    "height_diff = [torch.abs(y_pred[0][0][1] - y_true[0][1]).item() for y_pred, y_true in zip(preds, test_labels)]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Error in Pulse Height')\n",
    "plt.plot(np.arange(len(height_diff)), height_diff)\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Pulse Height Predicted vs Target')\n",
    "#plt.plot(np.arange(len(preds)), [pred[0][0][1].item() for pred in preds], label='Predicted')\n",
    "#plt.plot(np.arange(len(test_labels)), [label[0][1].item() for label in test_labels], label='Target')\n",
    "plt.scatter(np.arange(len(preds)), [pred[0][0][1].item() for pred in preds], label='Predicted')\n",
    "plt.scatter(np.arange(len(test_labels)), [label[0][1].item() for label in test_labels], marker='+', label='Target')\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Pulse Height (a.u.)')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "print(f'Mean height error: {np.mean(height_diff)}, Mean height error ratio: {np.mean(height_diff)/np.mean([target[0][1] * -1 for target in test_labels])}')\n",
    "print(f'median height error: {np.median(height_diff)}, median height error ratio: {np.median(height_diff)/np.median([target[0][1] * -1 for target in test_labels])}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "for target, pred in zip(np.array(test_labels)[20:30], preds[20:30]):\n",
    "   plt.figure()\n",
    "   pred_phase_resp = pred[0][0][1].item()\n",
    "   target_phase_resp = target[0][1].item()\n",
    "   tgt, pred = np.ones(11), np.ones(11)\n",
    "   tgt[5] = target_phase_resp\n",
    "   pred[5] = pred_phase_resp\n",
    "   plt.plot(np.arange(11), tgt, label='target')\n",
    "   plt.plot(np.arange(11), pred, label='pred')\n",
    "   plt.legend()\n",
    "   plt.show()\n",
    "   print(f'Diff: {np.abs(target_phase_resp - pred_phase_resp)}')\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### The model seems to be doing very well predicting the photon arrival time (looks like average error is ~5us) but not so well predicting the non-normalized phase response peaks. This seems to make sense because the phase response is affected by noise whereas the previous models were trained only on a set number of possible pulse heights. Since we aren't tied to the phase response transformation that the optimal filter is, I think a good step would be to try and normalize the phase response pulses. The loss also seems to be concentrated in the arrival time space, meaning it may be a good idea to separate the two from a loss function perspective (or maybe even creating a separate FC network just for phase response)."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Prediction and Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot a histogram of the quasiparticle perturbation predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram of all values and then plot\n",
    "qp_preds = np.array([pred[0][0][1] for pred in preds]) * -1\n",
    "counts, bins = np.histogram(qp_preds, range=(0.1, qp_preds.max() + (0.2 * qp_preds.max())), bins=200)\n",
    "\n",
    "# Recover true pulse heights from the test label data\n",
    "qp_true = np.unique([target.squeeze()[1].item() for target in test_labels])\n",
    "\n",
    "# Lets plot the histogram\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Predicted Pulse Heights')\n",
    "plt.stairs(counts, bins)\n",
    "\n",
    "# Need to add in the true pulse heights\n",
    "for target in qp_true:\n",
    "    pass\n",
    "    #plt.axvline(target * -1, c='r')\n",
    "plt.xlabel('Pulse Height')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram of all values and then plot\n",
    "targets = np.array([target.squeeze()[1].item() for target in test_labels]) * -1\n",
    "counts, bins = np.histogram(targets, range=(0.1, targets.max() + (0.2 * targets.max())), bins=200)\n",
    "\n",
    "# Lets plot the histogram\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Target Pulse Heights (Normalized)')\n",
    "plt.stairs(counts, bins)\n",
    "plt.xlabel('Pulse Height')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "targets = stream_to_height(arrs_test, theta1_test, norm=False)\n",
    "counts, bins = np.histogram(targets, range=(targets.min() + (0.2 * targets.min()), 0.1), bins=50)\n",
    "\n",
    "# Lets plot the histogram\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Target Pulse Heights (Raw)')\n",
    "plt.stairs(counts, bins)\n",
    "plt.xlabel('Pulse Height')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}

{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Visualization of model performance"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pathlib\n",
    "import random\n",
    "import torch\n",
    "import numpy as np\n",
    "from pathlib import Path\n",
    "import matplotlib.pyplot as plt\n",
    "from torch.utils.data import TensorDataset\n",
    "\n",
    "from models import ConvRegv2\n",
    "from mlcore.training import make_predictions\n",
    "from mlcore.eval import plot_stream_data\n",
    "from mlcore.dataset import load_training_data, stream_to_arrival, stream_to_height"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Model Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load model\n",
    "MODEL_DIR = pathlib.Path().cwd() / 'trained_models'\n",
    "MODEL_FNAME = 'cnn_reg_1691168899.pt'\n",
    "RANDOM_SEED = 42\n",
    "TEST_RATIO = 0.2\n",
    "BATCH_SIZE = 32\n",
    "EDGE_PAD = 10\n",
    "WINDOW_SIZE = 1000\n",
    "NUM_SAMPLES = 1000\n",
    "\n",
    "model = ConvRegv2(2, BATCH_SIZE)\n",
    "model.load_state_dict(torch.load(MODEL_DIR / MODEL_FNAME))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Loading"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define dataset locations and load the training and test data\n",
    "test_dir = Path('../../../data/pulses/test/single_pulse/variable_qp_density/raw_iq')\n",
    "train_dir = Path('../../../data/pulses/train/single_pulse/variable_qp_density/raw_iq')\n",
    "fname = Path(f'vp_single_num{NUM_SAMPLES}_win{WINDOW_SIZE}_pad{EDGE_PAD}.npz')\n",
    "labels = ('i', 'q', 'photon_arrivals', 'qp_density')\n",
    "i_test, q_test, arrs_test, qp_density_test = load_training_data(test_dir / fname, labels=labels)\n",
    "i_train, q_train, arrs_train, qp_density_train = load_training_data(train_dir / fname, labels=labels)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Transformations"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now we want to expand the dimensions for the i and q streams\n",
    "# since they will be used as input samples.\n",
    "i_test = np.expand_dims(i_test, axis=1)\n",
    "i_train = np.expand_dims(i_train, axis=1)\n",
    "q_test = np.expand_dims(q_test, axis=1)\n",
    "q_train = np.expand_dims(q_train, axis=1)\n",
    "\n",
    "# Get pulse heights and photon arrival values\n",
    "target_arrs_train = stream_to_arrival(arrs_train)\n",
    "target_arrs_test = stream_to_arrival(arrs_test)\n",
    "target_qpd_train = stream_to_height(arrs_train, qp_density_train)\n",
    "target_qpd_test = stream_to_height(arrs_test, qp_density_test)\n",
    "\n",
    "# Now we want to convert the loaded data to tensors.\n",
    "# Shape for targets is NUM_SAMPLES x 1 x 2\n",
    "# Shape for inputs is NUM_SAMPLES x 2 x WINDOW_SIZE\n",
    "X_train = torch.Tensor(np.hstack((i_train, q_train))) \n",
    "X_test = torch.Tensor(np.hstack((i_test, q_test)))\n",
    "y_train = torch.Tensor(np.stack((target_arrs_train, target_qpd_train), axis=2)) \n",
    "y_test = torch.Tensor(np.stack((target_arrs_test, target_qpd_test), axis=2))\n",
    "\n",
    "# From the newly created tensors, create testing and training datasets\n",
    "train_dataset = TensorDataset(X_train, y_train)\n",
    "test_dataset = TensorDataset(X_test, y_test)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model Predictions and Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Pick k random samples/labels from the test data and plot them along with the predictions\n",
    "test_samples = []\n",
    "test_labels = []\n",
    "\n",
    "for sample, label in random.sample(list(test_dataset), k=len(test_dataset)): # random.sample samples k elements from the given population without replacement; returns list of samples.\n",
    "    test_samples.append(sample)\n",
    "    test_labels.append(label)\n",
    "\n",
    "print(f'Test Sample Shape: {test_samples[0].shape}, Test Label Shape: {test_labels[0].shape}')\n",
    "preds = make_predictions(model, [x.unsqueeze(dim=0) for x in test_samples]) # returns a tensor\n",
    "print(f'Preds shape {preds[0].shape}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Since the train/test loss was so low and the absolute error was low, lets determine the difference between the predicted and\n",
    "# target arival times and plot this\n",
    "# Note the multiplication by 1000 to get back to the arrival time element\n",
    "arrival_diff = [torch.abs(WINDOW_SIZE * y_pred[0][0][0] - WINDOW_SIZE * y_true[0][0]).item() for y_pred, y_true in zip(preds, test_labels)]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Photon Arrival Time Error')\n",
    "plt.plot(np.arange(len(arrival_diff)), arrival_diff)\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Error (us)')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now that the error is known, let's plot the actual values for both the predictions and the targets\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Photon Arrival Time Predicted vs Target')\n",
    "#plt.plot(np.arange(len(preds)), [WINDOW_SIZE*pred[0][0][0].item() for pred in preds], label='Predicted')\n",
    "#plt.plot(np.arange(len(test_labels)), [WINDOW_SIZE*label[0][0].item() for label in test_labels], label='Target')\n",
    "plt.scatter(np.arange(len(preds)), [WINDOW_SIZE*pred[0][0][0].item() for pred in preds], marker='+', label='Predicted')\n",
    "plt.scatter(np.arange(len(test_labels)), [WINDOW_SIZE*label[0][0].item() for label in test_labels], label='Target')\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Photon Arrival (us)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Now lets do the same with the pulse height\n",
    "height_diff = [torch.abs(y_pred[0][0][1] - y_true[0][1]).item() for y_pred, y_true in zip(preds, test_labels)]\n",
    "\n",
    "plt.figure()\n",
    "plt.title('Error in Pulse Height')\n",
    "plt.plot(np.arange(len(height_diff)), height_diff)\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Error')\n",
    "plt.show()\n",
    "\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Pulse Height Predicted vs Target')\n",
    "#plt.plot(np.arange(len(preds)), [pred[0][0][1].item() for pred in preds], label='Predicted')\n",
    "#plt.plot(np.arange(len(test_labels)), [label[0][1].item() for label in test_labels], label='Target')\n",
    "plt.scatter(np.arange(len(preds)), [pred[0][0][1].item() for pred in preds], label='Predicted')\n",
    "plt.scatter(np.arange(len(test_labels)), [label[0][1].item() for label in test_labels], marker='+', label='Target')\n",
    "plt.xlabel('Test Sample')\n",
    "plt.ylabel('Pulse Height (a.u.)')\n",
    "plt.legend()\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Energy Prediction and Resolution"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Let's plot a histogram of the quasiparticle perturbation predictions from the model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create the histogram of all values and then plot\n",
    "qp_preds = np.array([pred[0][0][1] for pred in preds])\n",
    "counts, bins = np.histogram(qp_preds, range=(0.5, qp_preds.max() + (0.2 * qp_preds.max())), bins=100)\n",
    "\n",
    "# Recover true pulse heights from the test label data\n",
    "qp_true = np.unique([target.squeeze()[1].item() for target in test_labels])\n",
    "\n",
    "# Lets plot the histogram\n",
    "plt.figure(figsize=(12,7))\n",
    "plt.title('Predicted Pulse Heights')\n",
    "plt.stairs(counts, bins)\n",
    "\n",
    "# Need to add in the true pulse heights\n",
    "for target in qp_true:\n",
    "    plt.axvline(target, c='r')\n",
    "plt.xlabel('Pulse Height')\n",
    "plt.ylabel('Counts')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Based on the results, the model predictions have a systematic shift above the expected values. I think the test set needs to be much larger to get better idea of statistics."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "plot_stream_data('us',\n",
    "                 i=pulses[0][0],      \n",
    "                 q=pulses[0][1],\n",
    "                 photon_arrivals=pulses[0][2],\n",
    "                 qp_density=pulses[0][3],\n",
    "                 phase_response=pulses[0][4])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.11"
  },
  "orig_nbformat": 4
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
